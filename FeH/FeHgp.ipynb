{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved\n",
      "\n",
      "condition on dg_fpsf cut 22 inputs\n",
      "condition on dr_fpsf cut 23 inputs\n",
      "condition on di_fpsf cut 6 inputs\n",
      "condition on dz_fpsf cut 2 inputs\n",
      "condition on dy_fpsf cut 14 inputs\n",
      "condition on dCaHK_0 cut 14 inputs\n",
      "condition on du_0 cut 158 inputs\n",
      "condition on dFeHadop cut 280 inputs\n",
      "10.66% of inputs cut\n"
     ]
    }
   ],
   "source": [
    "#options\n",
    "metCut = 1\n",
    "cutLogg = True\n",
    "norm = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from metaimports import *\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as gpr\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from modelValidator import psMetric, cut, shuffleDwarfs, plotRes, plot, norm_inputs\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib.pyplot import figure\n",
    "fits = fitsParser(includefile = 'FeHdata.txt')\n",
    "cut(fits)\n",
    "\n",
    "if cutLogg:\n",
    "    #dwarfs = fits.data\n",
    "    dwarfs = (fits.data.sample(frac = 1, random_state = int(1000*np.random.rand())))\n",
    "    dwarfs = dwarfs[dwarfs['logg']>3.5]\n",
    "else:\n",
    "    dwarfs = shuffleDwarfs(fits)\n",
    "\n",
    "metPoorDwarfs = dwarfs[dwarfs['FeHadop']<metCut]\n",
    "metRichDwarfs = dwarfs[dwarfs['FeHadop']>metCut]\n",
    "din = metPoorDwarfs[fits.colours]\n",
    "if norm:\n",
    "    normParams = norm_inputs(din)\n",
    "dout = metPoorDwarfs[fits.outputs]\n",
    "din_train, din_test, dout_train, dout_test = train_test_split(din,dout, test_size = 0.7, shuffle = False)\n",
    "#din_train = din_train.sample(frac = 1, random_state = int(1000*np.random.rand()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f637a630ee2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdin_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    230\u001b[0m             optima = [(self._constrained_optimization(obj_func,\n\u001b[1;32m    231\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                                                       self.kernel_.bounds))]\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# Additional runs are performed from log-uniform chosen initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.pyc\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mtheta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvergence_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvergence_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 warnings.warn(\"fmin_l_bfgs_b terminated abnormally with the \"\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.pyc\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0;32m--> 224\u001b[0;31m                         theta, eval_gradient=True)\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.pyc\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# compare Equation 5.9 from GPML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ik,jk->ijk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# k: output-dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mcho_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0;31m# Compute \"0.5 * trace(tmp.dot(K_gradient))\" without\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;31m# constructing the full matrix tmp.dot(K_gradient) since only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watkinsz/anaconda3/envs/py2/lib/python2.7/site-packages/scipy/linalg/decomp_cholesky.pyc\u001b[0m in \u001b[0;36mcho_solve\u001b[0;34m(c_and_lower, b, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mpotrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lapack_funcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'potrs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError('illegal value in %d-th argument of internal potrs'\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernel1 = RBF(length_scale = 0.5)\n",
    "kernel2 = WhiteKernel(noise_level = 0.1)\n",
    "kernel = kernel1 + kernel2\n",
    "\n",
    "\n",
    "params = {\n",
    "    'kernel' : kernel,\n",
    "    'n_restarts_optimizer' : 0,\n",
    "    'normalize_y' : True,\n",
    "    'copy_X_train' : False,\n",
    "    'alpha' : 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = gpr(**params)\n",
    "model.fit(din_train, dout_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getbins = lambda data, size = 0.1 : np.arange(min(data), max(data) + size, size)\n",
    "metPoorDwarfs['test_flag'] = np.append(np.zeros(len(din_train)),np.ones(len(din_test)))\n",
    "metRichDwarfs['test_flag'] = [-1]*len(metRichDwarfs)\n",
    "output = metPoorDwarfs.append(metRichDwarfs).sort_index()\n",
    "check = filter(lambda x : x != 'test_flag' , output.keys())\n",
    "#assert (output[check].sort_index() == dwarfs).all().all()\n",
    "inp = output[fits.colours]\n",
    "if norm:\n",
    "    for field in fits.colours:\n",
    "        inp[field] = (inp[field] - normParams[field][0])*1.0/normParams[field][1]\n",
    "        \n",
    "output['FeH_pred'] = model.predict(inp)\n",
    "output['res'] = output['FeH_pred'] - output['FeHadop']\n",
    "output = output.reset_index()\n",
    "x = plotRes((output['res'])[output['test_flag']==1], (output['res'])[output['test_flag']==0], metLabel = '[Fe/H]<%.2f'%metCut, size = 0.05,\n",
    "       xy = (257, 195) , normalFit  = False)\n",
    "toPlot = (output[output['FeHadop']<metCut])['FeHadop']\n",
    "toPlot -= np.mean(toPlot)\n",
    "toPlot *= -1\n",
    "plt.hist(toPlot, histtype = 'step' , bins = getbins(toPlot, size = 0.05), density = True, label = 'mean(exp) - exp')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot((output['res'])[output['test_flag']==-1])\n",
    "\n",
    "plt.scatter(output['FeHadop'], output['FeH_pred'] , s = 0.5)\n",
    "plt.title('Predicted v.s. Expected [Fe/H]')\n",
    "plt.xlabel('[Fe/H] (Expected)')\n",
    "plt.ylabel('[Fe/H] (Predicted)')\n",
    "x = np.linspace(max((plt.xlim())[0], (plt.ylim())[0]), min((plt.xlim())[1], (plt.ylim())[1]))\n",
    "plt.plot(x,x, color = 'black')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter((output[output['FeHadop']<metCut])['FeHadop'], (output[output['FeHadop']<metCut])['FeH_pred'] , s = 0.5)\n",
    "plt.title('Predicted v.s. Expected [Fe/H]')\n",
    "plt.xlabel('[Fe/H] (Expected)')\n",
    "plt.ylabel('[Fe/H] (Predicted)')\n",
    "x = np.linspace(max((plt.xlim())[0], (plt.ylim())[0]), min((plt.xlim())[1], (plt.ylim())[1]))\n",
    "plt.plot(x,x, color = 'black')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "getbins = lambda data, size = 0.1 : np.arange(min(data), max(data) + size, size)\n",
    "den = False\n",
    "getNbins = lambda data, s ,size = 0.1 : int((np.max(data[s])-np.min(data[s]))/size)\n",
    "try:\n",
    "    plt.hist((output['FeH_pred'])[output['test_flag']==-1], bins  = getbins((output['FeH_pred'])[output['test_flag']==-1]),  histtype = 'step', label = 'Predicted | [Fe/H]>%.1f'%metCut, density = den)\n",
    "except ValueError:\n",
    "    pass\n",
    "plt.hist((output['FeHadop']), bins = getbins((output['FeHadop'])), histtype = 'step', label = 'Expected', density = den)\n",
    "plt.hist((output['FeH_pred'])[output['test_flag']>=0], bins=getbins((output['FeH_pred'])[output['test_flag']>=0]),  histtype = 'step', label = 'Predicted | [Fe/H]<%.1f'%metCut, density = den)\n",
    "plt.xlabel('[Fe/H]')\n",
    "plt.title('Distributions of Predicted and Expected Metallicities', fontsize = 15)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bins = [0, -0.5, -1,-1.5, -2 , -3]\n",
    "f,  z = plt.subplots(1, len(bins), sharex='all', sharey='row')\n",
    "plt.xlim(-2,2)\n",
    "f.set_size_inches(18.5, 10.5)\n",
    "for i in range(len(bins)):\n",
    "    if (i==len(bins)-1):\n",
    "        sub = output[output['FeHadop']<bins[i]]\n",
    "    else:\n",
    "        sub = output[(output['FeHadop']<bins[i])&(output['FeHadop']>bins[i+1])]\n",
    "    Title = '%.1f<[Fe/H]<%.1f' %(bins[i+1] ,bins[i]) if i+1 in range(len(bins)) else '[Fe/H]<%.1f'%bins[i]\n",
    "    plotRes((sub[sub['test_flag']!=0])['res'], (sub[sub['test_flag']==0]['res']), toPlot = z[i],title = Title, normalFit = False, xy = (0.1 , 0.9))\n",
    "z[0].legend(loc = 'upper left')\n",
    "f.text(0.5, 0.08, '[Fe/H] predicted - expected', ha='center', fontsize = 15)\n",
    "f.text(0.09, 0.5, 'Probability Density', va='center', rotation='vertical', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = [-1, -1.5 , -2, -2.5, -3]\n",
    "pur , com = psMetric(output, inc = inc)\n",
    "def printTable(inc, pur, com):\n",
    "    table = \"\"\n",
    "    table += '| [Fe/H]< | purity | completness |'\n",
    "    table += '\\n'+'-'*len(table)+'\\n'\n",
    "    for i in range(len(inc)):\n",
    "        if pur[i]>=0:\n",
    "            table+= '| %-8.1f| %6.4f | %-11.4f |\\n'%(inc[i],pur[i],com[i])\n",
    "        else: table+= '| %-8.1f| %5.3f | %-11.4f |\\n'%(inc[i],pur[i],com[i])\n",
    "    return table\n",
    "            \n",
    "print printTable(inc,pur,com)\n",
    "#joblib.dump(model, 'min%scutnn'% str(-1*metCut))\n",
    "#save_data(output, 'min2cut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
